---
title: 'AI, Singularity, and Product Management'
description: "Time for a new version with a lot of breaking changes! Have fun everybody."
date: 2025-02-08
draft: true
---

The theory of AGI super acceleration is that once AI is able to sufficiently self-improve, it will take off in an exponential curve and become so intelligent that we cannot possibly predict what it will do or what will happen after that point. See the ["Paperclip Maximizer" thought experiment](https://en.wikipedia.org/wiki/Instrumental_convergence#Paperclip_maximizer) to see the most extreme version of this. I personally don't believe in this outcome and here's why …

## AI, meet the real world

The human mind, much like a computer, operates by building and maintaining an approximate simulation of the external world. Crucially, almost all *new* knowledge is discovered through interaction with that external world – by testing hypotheses against reality. Babies learn to walk through trial and error, observing their own movements and the world's responses. Scientists discover new drugs by observing their effects on biological systems. Pure theory, while powerful, rarely leads to breakthroughs in isolation. Experimentation and contact with the messy, unpredictable real world are almost always necessary for validation. Einstein's Theory of Relativity, a monumental theoretical achievement, still required the observation of light bending during a solar eclipse to be empirically confirmed.


<div class="details flow">
    <details id="title">
      <summary>Notable exceptions ... </summary>
While I acknowledge exceptions, I don't believe they fundamentally alter the core argument:

*   **Synthesis Across Diverse Knowledge:** Superintelligent AI, with vast knowledge across diverse fields, could potentially make novel discoveries by connecting the dots in ways humans haven't. 
*   **Deduction on Known Knowledge:** Superintelligent AI, with superhuman reasoning abilities, could deduce new knowledge from existing data. However, real world validation quickly becomes necessary as deduction strays further from the base knowledge. 
*   **Theoretical Sciences:** Certain fields, like cryptography and pure mathematics, are less reliant on direct interaction with the physical world. These areas might see more rapid advancements driven by AI. But even here, applications of these theoretical advancements often require real-world implementation and testing.
    </details>
</div>

My central argument is that AI's progress towards a singularity is fundamentally constrained by the need for interaction with and observation of the real world. This world is messy, complex, slow-moving, and presents challenges in perception and manipulation that AI is still far from mastering. Contact with the real world acts as an unavoidable "friction" on the discovery of new knowledge. This doesn't mean AI won't continue to develop rapidly, but it will likely slow progress down to timescales more comparable to human endeavors.

{% css "local" %}
  {% include "css/details.css" %}
{% endcss %}

{% js "defer" %}
  {% include "scripts/details.js" %}
{% endjs %}


Shifting from the theoretical to the practical, let's consider the implications for my own field: Product Management. Will PMs be replaced by polite, efficient chatbots anytime soon? I believe the answer to this question, and for any profession, hinges on the degree of real-world interaction required.

Product management, at its core, revolves around three key pillars:

1.  **Discovery:** Gathering and analyzing diverse information sources to inform product strategy. This includes direct customer interaction (interviews, surveys, user testing), competitor analysis, market research, and internal innovation assessments.
2.  **Execution:** Collaborating with design and engineering teams to translate discoveries and product plans into a functional product. This involves constant communication, negotiation, and problem-solving.
3.  **Sales (Influence & Advocacy):** "Sales" in this context is broader than just selling to customers. It encompasses communicating the product vision, value proposition, and launch plan to both internal stakeholders (to secure resources and alignment) and external audiences (customers, partners).

Across all three pillars, "contact with the real world" is paramount. And the most crucial aspect of this contact is *communication*. All of these functions require extensive and nuanced communication with various parties, both inside and outside the company.

**The Communication Challenge: Beyond Simple Email**

Let's illustrate the complexity of communication with a seemingly simple example: email. Imagine we want an AI agent to fully manage a PM's inbox. What would it need to do, beyond just generating text?

*   **Whether to or When to Write the Email:** This is arguably the most challenging aspect. Many emails are proactive – triggered by noticing a gap, identifying an opportunity, or needing to bring people together around a potential problem. The decision of *if* and *when* to send an email depends on a complex web of factors, including:
    *   Understanding the current context of ongoing projects and conversations.
    *   Prioritizing tasks and issues based on strategic goals.
    *   Assessing the urgency and importance of different requests.
    *   Anticipating potential problems and proactively addressing them.
*   **Generating the Intent for the Email:** Before writing, the AI needs a clear understanding of the *purpose* of the email. Is it to inform, persuade, request action, gather feedback, or something else? This intent shapes the entire message.
*    **Write the email:** The AI needs to follow email and professional etiquette and adjust its tone to the situation.
*   **Who to Write the Email To:** Identifying the correct recipients (and CC/BCC recipients) requires understanding relationships, responsibilities, and the appropriate communication channels within the organization.
* **Reading and understanding incoming emails:** Responding to incoming emails in a relevant way and building the responses in the context of the conversation.
* **Following up on emails:** Knowing if/when to follow up and adapting to the feedback it is receiving.
*   **Nonverbal and subtle clues:** A phone call or a face-to-face chat are very different from an email - AI needs to recognize body language, human emotion, etc.

This simple email example highlights the depth of contextual understanding, strategic thinking, and interpersonal skills required for effective communication – skills that are still primarily within the human domain.

**Conclusion: Augmentation, Not Replacement**

While AI will undoubtedly transform product management, I believe it will do so through *augmentation*, not complete replacement. AI can automate repetitive tasks, analyze vast datasets, personalize user experiences, and provide valuable insights. It can assist with drafting emails, scheduling meetings, summarizing documents, and even generating initial product ideas.

However, the core of product management – understanding human needs, building relationships, navigating complex organizational dynamics, making strategic decisions in the face of uncertainty, and driving innovation through real-world interaction – will remain firmly in the hands of human product managers. The future of product management is not about being replaced by AI, but about learning to leverage its power to become *more* effective, more insightful, and ultimately, more human. The singularity might be a distant theoretical possibility, but in the world of product management, we're entering an era of powerful human-AI collaboration.